#--------------------------------------------------------------------------------------
# Batch Scheduling Application
#-------------------------------------------------------------------------------------
spring.application.name=batch-scheduling
server.port=8085
server.servlet.context-path=/bss
#This parameter specifies the maximum size permitted for uploaded files. The default is 1MB.
spring.servlet.multipart.max-file-size=1024KB
#This parameter specifies the maximum size allowed for multipart/form-data requests. The default is 10MB.
spring.servlet.multipart.max-request-size=1228KB

# Swagger UI URL http://localhost:8085/bss/swagger-ui/index.html
# http://localhost:8085/bss/v2/api-docs
 # http://localhost:8085/bss/v3/api-docs

springdoc.swagger-ui.disable-swagger-default-url=true
messages.source.files.path=/opt/seamless/conf/batch-scheduling
logging.config=/opt/seamless/conf/batch-scheduling/log4j2.xml
## Workaround for SB-2.6.x and SpringFox which assumes that the path matching strategy of Spring MVCant-path-matcher. However the default matching strategy of Spring Boot 2.6.x is path-pattern-matcher
#spring.mvc.pathmatch.matching-strategy=ant-path-matcher
spring.mvc.pathmatch.matching-strategy=path-pattern-parser

#-------------------------------------------------------------------------------------
# ElastiSearch  properties
#-------------------------------------------------------------------------------------
bss.elasticsearch.userName=elastic
bss.elasticsearch.password=seamless
bss.elasticsearch.1.url=svc-haproxy
bss.elasticsearch.1.port=9200
#bss.elasticsearch.2.url=localhost
#bss.elasticsearch.2.port=9200
#-------------------------------------------------------------------------------------
# Database connection properties
#-------------------------------------------------------------------------------------
spring.datasource.url=jdbc:mariadb://svc-haproxy:4306/batchschedulingsystem
spring.datasource.username=refill
spring.datasource.password=refill
#-------------------------------------------------------------------------------------
# JPA properties
#-------------------------------------------------------------------------------------
spring.jpa.database-platform=org.hibernate.dialect.MariaDBDialect
spring.jpa.properties.hibernate.format_sql=true
spring.jpa.properties.hibernate.jdbc.time_zone=UTC

#-------------------------------------------------------------------------------------
# Thymeleaf configuration
#-------------------------------------------------------------------------------------
spring.thymeleaf.check-template-location=true
spring.thymeleaf.prefix=file:/opt/seamless/conf/batch-scheduling/notifications/
spring.thymeleaf.suffix=.txt
spring.thymeleaf.mode=TEXT
spring.thymeleaf.encoding=UTF-8
spring.thymeleaf.content-type=text/plain
spring.thymeleaf.cache=false

#-------------------------------------------------------------------------------------
# CORS config
#-------------------------------------------------------------------------------------
cors.enable=false
#comma separated origin list
cors.allowedorigins=http://localhost:9090,http://localhost:9091
#-------------------------------------------------------------------------------------
# Localization config
#-------------------------------------------------------------------------------------
bss.supported.languages=en,ar,fr

#-------------------------------------------------------------------------------------
# Batch properties
#-------------------------------------------------------------------------------------
### clientId will be helpfull to distinguish the client
### for which ftl should be used and below config will
### be used in bss.freemarker.file.path
#bss.freemarker.clientId=tt
bss.freemarker.file.path=/opt/seamless/conf/batch-scheduling/templates
###/${bss.freemarker.clientId}

bss.tmp.file.path=/var/tmp

### turn this property to true to merge error and retry file
bss.retry.file.merge=false

#-------------------------------------------------------------------------------------
# Pending Jobs DB Scanner properties
#-------------------------------------------------------------------------------------
# Frequency to scan db for jobs that are pending to be scheduled
bss.pendingJobScanner.frequency.milliseconds=40000
# Scan jobs that are older than <olderThan> seconds
bss.pendingJobScanner.olderThan.milliseconds=60000
# Limit number of jobs to be run
bss.pendingJobScanner.nbjobs.limit=10

#-------------------------------------------------------------------------------------
# OSM service connection (Object Store Manager)
#-------------------------------------------------------------------------------------
bss.osmApi.url=http://svc-object-store:3000/osm
bss.osmApi.uri=/v1/resource/
bss.osmApi.connectionTimeout=5000
bss.osmApi.requestTimeout=60000
#-------------------------------------------------------------------------------------
# Inventory Management System (through nginx)
#-------------------------------------------------------------------------------------
bss.imsApi.url=http://svc-nginx:18080/api/ims
bss.imsApi.connectionTimeout=5000
bss.imsApi.requestTimeout=60000
bss.imsApi.importInventoryUri=/v1/bulk-import
bss.imsApi.updateInventoryUri=/v1/inventory/update/bulk-import
# As per release 1.0.1
bss.imsApi.deleteInventoryUri=/v1/batches
#-------------------------------------------------------------------------------------
# Dealer Management System (through nginx)
#-------------------------------------------------------------------------------------
bss.dmsApi.url=http://svc-nginx:18080/api/dms
bss.dmsApiV2.url=http://svc-nginx:18080/api/dms
bss.dmsApi.connectionTimeout=5000
bss.dmsApi.requestTimeout=60000
bss.dmsApi.socketTimeout=60000
bss.dmsApi.importResellerUri=/v1/resellers/create
bss.dmsApi.updateResellerUri=/v2/auth/bulkUpdate
bss.dmsApi.bulkAddResellerUsersUri=/v1/resellers/bulkAddResellerUsers
#as per release 1.0.1
#bss.dmsApi.bulkUpdateResellerUsersUri=/v2/auth/bulkUpdate
bss.dmsApi.bulkUpdateResellerUsersUri=/v1/resellers/bulkUpdateResellerUsers
bss.dmsApi.bulkDeleteResellerUsersUri=/v1/resellers/bulkDeleteResellerUsers

bss.dmsApi.changeResellerParentUri=/v2/auth/bulkChangeParent
bss.dmsApi.changeResellerStateUri=/auth/v1/resellerChangeState
bss.dmsApi.searchResellersByAttributeUri=/auth/bulkSearchResellersByAttribute

bss.dmsApi.getResellerInfoUri=/auth/getResellerInfo

#-------------------------------------------------------------------------------------
# Order Management System (through nginx)
#-------------------------------------------------------------------------------------

bss.omsApi.url=http://svc-nginx:18080/api/oms
bss.omsApi.connectionTimeout=5000
bss.omsApi.requestTimeout=60000

bss.omsApi.formDataEnabled=false
### if bss.omsApi.omsFormDataEnabled=true then below url should be /v1/orders
### incase of bss.omsApi.formDataEnabled=false below url should be /v2/orders
#bss.omsApi.importOrderUri=/v1/orders
bss.omsApi.importOrderUri=/v2/orders

#-------------------------------------------------------------------------------------
# HTTPStatus Codes List to be used for event success or failed accordingly
#-------------------------------------------------------------------------------------
bss.list.httpSuccessCodes=200,202

#-------------------------------------------------------------------------------------
# RateCard Configuration (through nginx)
#-------------------------------------------------------------------------------------
bss.rateCardApi.url=http://svc-nginx:18080/api/els
bss.rateCardApi.uri=/v1/ratecard
bss.rateCardApi.connectionTimeout=5000
bss.rateCardApi.resquestTimeout=60000

#-------------------------------------------------------------------------------------
# Authentication Configuration (through nginx)
#-------------------------------------------------------------------------------------
bss.idmsApi.baseUrl=http://svc-nginx:18080
bss.idmsApi.loginUri=/login-backend
bss.idmsApi.loginChannel=SEAMLESS-UNIFIED
# TODO MKS: Need enhancements
bss.idmsApi.loginUserId=OPERATOR
bss.idmsApi.loginPassword=2023
#-------------------------------------------------------------------------------------
# TXE (through nginx)
#-------------------------------------------------------------------------------------

bss.txeApi.url=http://svc-nginx:18080/api/txe
bss.txeApi.importTransferUri=/v1/bulkRequestTransfer
bss.txeApi.importTransferReversalUri=/v1/bulkReversalRequest
bss.txeApi.connectionTimeout=5000
bss.txeApi.requestTimeout=60000

#-------------------------------------------------------------------------------------
# SCC-Engine (through nginx)
#-------------------------------------------------------------------------------------

bss.sccApi.bulkimportParticipateTargetAudience=http://svc-nginx:18080/api/scc/v1/campaign/participate-target-audience
bss.sccApi.connectionTimeout=5000
bss.sccApi.requestTimeout=60000

#-------------------------------------------------------------------------------------
# Notification Manager (through nginx)
#-------------------------------------------------------------------------------------
bss.notification.management.proxy.uri=http://svc-nginx:18080/api/notificationmanager
rest.template.http.max.idle=50000
rest.template.http.keep.alive=30000
rest.template.http.connection.timeout=20000
rest.template.http.read.timeout=20000

bss.notification.language.default=en_US
bss.notification.sender.email=noreply@seamless.se
bss.notification.sender.sms=Seamless
# List of recipients to notify. Empty or list amongst ADMIN and SUBMITTER
bss.notification.recipients=ADMIN,SUBMITTER
# Possible values:
# BOTH: send notification by SMS and eMail
# SMS: when the recipient has an MSISDN sends the notification by SMS otherwise by eMail
# EMAIL: when the recipient has an e-mail sends the notification by eMail otherwise by SMS
bss.notification.submitter.preferred.channel=BOTH
bss.notification.admin.preferred.channel=BOTH
bss.notification.admin.msisdn=21690xxxxxx
bss.notification.admin.email=test@seamless.se


#-------------------------------------------------------------------------------------
# Unified Client - Reference Generator
#-------------------------------------------------------------------------------------
bss.ersReferenceGenerator.class_name=com.seamless.common.referencegeneration.TimestampReferenceGenerator
bss.ersReferenceGenerator.timestamp_repeat_warning_count=10
bss.ersReferenceGenerator.reference_counter_length=10
bss.ersReferenceGenerator.node_id=01

#-------------------------------------------------------------------------------------
# Batch Reseller specific properties
#-------------------------------------------------------------------------------------

# Map enabled field to status
bss.reseller.mapping.enabledToStatus={'1':'Active', '0':'Deactivated', 'default':'Deactivated'}
bss.reseller.mapping.flagToBoolean={'0':'false', '1':'true', 'default':'false'}
#bss.reseller.updateSubType=Users_Unitel_Update

bss.reseller.fieldValidationRegExp={\
    'phone':'(216)?[0-9]{8}' ,\
    'username':'[A-Z0-9-_]+' \
    }
bss.reseller.defaultAllowedFor=NONE

bss.reseller.id=Generic
bss.reseller.allowedFor=${bss.reseller.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.reseller.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.reseller.processor.schedTime=0 0 1 * * ?
bss.reseller.processor.schedTypeDelay-sec=60
bss.reseller.processor.failOnError=false
bss.reseller.processor.chunkSize=10
# Number of chunks executed in parallel
# bss.reseller.processor.parallelChunkNb=10
bss.reseller.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.reseller.processor.retryDelay=10
bss.reseller.file.uploadDescription=Reseller ${bss.reseller.id} import file
bss.reseller.file.supportedFormats=CSV,JSON
bss.reseller.file.format=CSV
bss.reseller.file.csv.freemarkerTemplate=reseller_import.ftl
bss.reseller.file.csv.header=fullname,cin,phone,gouvernorat_id,delegation_id,code_postal_id,address,fax,matricule_fiscal,username,otp,password,enabled,motif_desactivation,email,groupe,parent_user,code_conventionnel,digitalised,allowreport,allow_webservice_sell,email_responsable,Localisation
bss.reseller.file.csv.hasHeader=true
bss.reseller.file.csv.defaultSeparator=;
bss.reseller.file.csv.fieldMapping.resellerId=COLUMN:username
bss.reseller.file.csv.fieldMapping.resellerName=COLUMN:fullname
bss.reseller.file.csv.fieldMapping.resellerMSISDN=COLUMN:phone
bss.reseller.file.csv.fieldMapping.resellerTypeId=COLUMN:groupe
bss.reseller.file.csv.fieldMapping.parentResellerId=COLUMN:parent_user
bss.reseller.file.csv.fieldMapping.status=MAP_COLUMN:enabledToStatus:enabled
bss.reseller.file.csv.fieldMapping.address_email=COLUMN:email
#bss.reseller.file.csv.fieldMapping.address_fax=COLUMN:fax
bss.reseller.file.csv.fieldMapping.address_street=COLUMN:address
#bss.reseller.file.csv.fieldMapping.address_zip=COLUMN:code_postal_id
bss.reseller.file.csv.fieldMapping.extraParam_region=COLUMN:gouvernorat_id
bss.reseller.file.csv.fieldMapping.extraParam_delegation=COLUMN:delegation_id
bss.reseller.file.csv.fieldMapping.extraParam_matricule_fiscal=COLUMN:matricule_fiscal
bss.reseller.file.csv.fieldMapping.extraParam_customer_national_identification_id=COLUMN:cin
bss.reseller.file.csv.fieldMapping.extraParam_one_time_password=COLUMN:otp
bss.reseller.file.csv.fieldMapping.extraParam_motte_de_passe=COLUMN:password
bss.reseller.file.csv.fieldMapping.extraParam_reason_for_activation=COLUMN:motif_desactivation
bss.reseller.file.csv.fieldMapping.extraParam_code_external_system=COLUMN:code_conventionnel
bss.reseller.file.csv.fieldMapping.extraParam_allow_mobile_app=COLUMN:digitalised
bss.reseller.file.csv.fieldMapping.extraParam_allow_report=COLUMN:allowreport
bss.reseller.file.csv.fieldMapping.extraParam_allow_mobile_sell=COLUMN:allow_webservice_sell
bss.reseller.file.csv.fieldMapping.extraParam_email_responsible=COLUMN:email_responsable
bss.reseller.file.csv.fieldMapping.extraParam_postal_code=COLUMN:code_postal_id
bss.reseller.file.csv.fieldMapping.extraParam_fax=COLUMN:fax
bss.reseller.file.csv.fieldMapping.extraParam_zone_localisation=COLUMN:Localisation
bss.reseller.file.csv.fieldValidationRegExp=${bss.reseller.fieldValidationRegExp}

#bss.reseller.file.csv.fieldMapping.user_userId=LIST_COLUMN:user0:USERID0

#-------------------------------------------------------------------------------------
# Batch Reseller Users
#-------------------------------------------------------------------------------------
# Map enabled field to status
bss.reselleruser.mapping.enabledToStatus={'1':'Active', '0':'Deactivated', 'default':'Deactivated'}
bss.reselleruser.mapping.flagToBoolean={'0':'false', '1':'true', 'default':'false'}
#bss.reselleruser.updateSubType=resellerUser_import

bss.reselleruser.fieldValidationRegExp={\
    'phone':'(216)?[0-9]{13}' ,\
    'name':'[A-Za-z0-9-_]+' \
    }
bss.reselleruser.defaultAllowedFor=NONE

bss.reselleruser.id=Generic
bss.reselleruser.allowedFor=${bss.reselleruser.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.reselleruser.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.reselleruser.processor.schedTime=0 0 1 * * ?
bss.reselleruser.processor.schedTypeDelay-sec=60
bss.reselleruser.processor.failOnError=false
bss.reselleruser.processor.chunkSize=10
# Number of chunks executed in parallel
# bss.reselleruser.processor.parallelChunkNb=10
bss.reselleruser.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.reselleruser.processor.retryDelay=10
bss.reselleruser.file.uploadDescription=Reseller ${bss.reselleruser.id} import file
bss.reselleruser.file.supportedFormats=CSV
bss.reselleruser.file.format=CSV
bss.reselleruser.file.csv.freemarkerTemplate=resellerUser_import.ftl
bss.reselleruser.file.csv.header=email,name,password,phone,record_id,reseller_id,role_id,user_id
bss.reselleruser.file.csv.hasHeader=true
bss.reselleruser.file.csv.defaultSeparator=;
bss.reselleruser.file.csv.fieldMapping.email=COLUMN:email
bss.reselleruser.file.csv.fieldMapping.name=COLUMN:name
bss.reselleruser.file.csv.fieldMapping.password=COLUMN:password
bss.reselleruser.file.csv.fieldMapping.phone=COLUMN:phone
bss.reselleruser.file.csv.fieldMapping.recordId=COLUMN:record_id
bss.reselleruser.file.csv.fieldMapping.resellerId=COLUMN:reseller_id
bss.reselleruser.file.csv.fieldMapping.roleId=COLUMN:role_id
bss.reselleruser.file.csv.fieldMapping.userId=COLUMN:user_id

bss.reselleruser.file.csv.fieldValidationRegExp=${bss.reselleruser.fieldValidationRegExp}


#-------------------------------------------------------------------------------------
# Batch Inventory specific properties
#-------------------------------------------------------------------------------------

# Map brand to productSKU
bss.inventory.mapping.dsaBrandToSKU={\
    'TT':'TT_SIM_DSA',\
    'CSS':'CSS_SIM_DSA',\
    'Elissa':'ESS_SIM_DSA',\
    'Tarajji':'TARAJI_SIM_DSA',\
    'default':'TT_SIM_DSA'\
    }
bss.inventory.mapping.nonDsaBrandToSKU={\
    '0001':'TT_SIM_NON_DSA',\
    '0004':'CSS_SIM_NON_DSA',\
    '0003':'ESS_SIM_NON_DSA',\
    '0002':'TARAJI_SIM_NON_DSA',\
    'default':'TT_SIM_NON_DSA'\
    }

bss.inventory.fieldValidationRegExp={\
    'MSISDN':'(216)?[0-9]{8}' \
    }

bss.inventory.defaultAllowedFor=ALL

#bss.resellerchangeparent.idbss.inventory.updateSubType=Serialized_Inventory_Safaricom_Update,Trackable_Inventory_Safaricom_Update

bss.inventory.id=Generic
bss.inventory.allowedFor=${bss.inventory.defaultAllowedFor}
bss.inventory.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.inventory.processor.schedTime=0 0 1 * * ?
bss.inventory.processor.schedTypeDelay-sec=30
bss.inventory.processor.failOnError=true
bss.inventory.processor.chunkSize=15
# Number of chunks executed in parallel
# bss.inventory.processor.parallelChunkNb=10
bss.inventory.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.inventory.processor.retryDelay=10
bss.inventory.file.uploadDescription=Inventory ${bss.inventory.id} import file
bss.inventory.file.supportedFormats=CSV,JSON
bss.inventory.file.format=CSV
bss.inventory.file.csv.freemarkerTemplate=inventory_import.ftl
bss.inventory.file.csv.header=SIM,BRAND,CODE_BRAND
bss.inventory.file.csv.hasHeader=true
bss.inventory.file.csv.defaultSeparator=;
bss.inventory.file.csv.fieldMapping.batchId=CONSTANT:
bss.inventory.file.csv.fieldMapping.owner=SYSTEM:uploadedBy
bss.inventory.file.csv.fieldMapping.startNo=CONSTANT:
bss.inventory.file.csv.fieldMapping.endNo=CONSTANT:
bss.inventory.file.csv.fieldMapping.state=CONSTANT:Available
bss.inventory.file.csv.fieldMapping.idType=CONSTANT:SERIAL
bss.inventory.file.csv.fieldMapping.serialNo=COLUMN:SIM
bss.inventory.file.csv.fieldMapping.locationId=SYSTEM:uploadedBy
bss.inventory.file.csv.fieldMapping.productSKU=MAP_COLUMN:dsaBrandToSKU:BRAND
bss.inventory.file.csv.fieldMapping.data_brandCode=COLUMN:CODE_BRAND

#-------------------------------------------------------------------------------------
# Inventory Import: Serialized
#-------------------------------------------------------------------------------------
bss.inventory.type[0].id=Serialized
bss.inventory.type[0].allowedFor=${bss.inventory.defaultAllowedFor}
bss.inventory.type[0].processor.schedType=scheduled
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.inventory.type[0].processor.schedTime=0 0 1 * * ?
bss.inventory.type[0].processor.schedTypeDelay-sec=30
bss.inventory.type[0].processor.failOnError=true
bss.inventory.type[0].processor.chunkSize=100
# Number of chunks executed in parallel
# bss.inventory.type[0].processor.parallelChunkNb=10
bss.inventory.type[0].file.uploadDescription=Inventory ${bss.inventory.type[0].id} import file
bss.inventory.type[0].file.supportedFormats=CSV
bss.inventory.type[0].file.format=CSV
bss.inventory.type[0].file.csv.freemarkerTemplate=inventory_import.ftl
bss.inventory.type[0].file.csv.header=Product SKU,Serial,Status,Owner
bss.inventory.type[0].file.csv.hasHeader=true
bss.inventory.type[0].file.csv.defaultSeparator=,
bss.inventory.type[0].file.csv.fieldMapping.productSKU=COLUMN:Product SKU
bss.inventory.type[0].file.csv.fieldMapping.serials_serialNumber=COLUMN:Serial
bss.inventory.type[0].file.csv.fieldMapping.state=COLUMN:Status
bss.inventory.type[0].file.csv.fieldMapping.batchId=SYSTEM:batchId
bss.inventory.type[0].file.csv.fieldMapping.serialNo=COLUMN:Serial
bss.inventory.type[0].file.csv.fieldMapping.owner=COLUMN:Owner
bss.inventory.type[0].file.csv.fieldMapping.locationId=COLUMN:Location


#-------------------------------------------------------------------------------------
# Inventory Import: Trackable
#-------------------------------------------------------------------------------------
bss.inventory.type[1].id=Trackable
bss.inventory.type[1].allowedFor=${bss.inventory.defaultAllowedFor}
bss.inventory.type[1].processor.schedType=scheduled
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.inventory.type[1].processor.schedTime=0 0 1 * * ?
bss.inventory.type[1].processor.schedTypeDelay-sec=30
bss.inventory.type[1].processor.failOnError=true
bss.inventory.type[1].processor.chunkSize=100
# Number of chunks executed in parallel
# bss.inventory.type[1].processor.parallelChunkNb=10
bss.inventory.type[1].file.uploadDescription=Inventory ${bss.inventory.type[1].id} import file
bss.inventory.type[1].file.supportedFormats=CSV
bss.inventory.type[1].file.format=CSV
bss.inventory.type[1].file.csv.freemarkerTemplate=inventory_import.ftl
bss.inventory.type[1].file.csv.header=Product SKU,Start Serial,End Serial,Status,Owner
bss.inventory.type[1].file.csv.hasHeader=true
bss.inventory.type[1].file.csv.defaultSeparator=,
bss.inventory.type[1].file.csv.fieldMapping.productSKU=COLUMN:Product SKU
bss.inventory.type[1].file.csv.fieldMapping.startNo=COLUMN:Start Serial
bss.inventory.type[1].file.csv.fieldMapping.endNo=COLUMN:End Serial
bss.inventory.type[1].file.csv.fieldMapping.status=COLUMN:Status
bss.inventory.type[1].file.csv.fieldMapping.owner=COLUMN:Owner
bss.inventory.type[1].file.csv.fieldMapping.locationId=COLUMN:Location
bss.inventory.type[1].file.csv.fieldMapping.batchId=SYSTEM:batchId


#-------------------------------------------------------------------------------------
# Inventory Import: Non-serialized
#-------------------------------------------------------------------------------------
bss.inventory.type[2].id=Non-serialized
bss.inventory.type[2].allowedFor=${bss.inventory.defaultAllowedFor}
bss.inventory.type[2].processor.schedType=scheduled
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.inventory.type[2].processor.schedTime=0 0 1 * * ?
bss.inventory.type[2].processor.schedTypeDelay-sec=30
bss.inventory.type[2].processor.failOnError=true
bss.inventory.type[2].processor.chunkSize=100
# Number of chunks executed in parallel
# bss.inventory.type[2].processor.parallelChunkNb=10
bss.inventory.type[2].file.uploadDescription=Inventory ${bss.inventory.type[2].id} import file
bss.inventory.type[2].file.supportedFormats=CSV
bss.inventory.type[2].file.format=CSV
bss.inventory.type[2].file.csv.freemarkerTemplate=inventory_import.ftl
bss.inventory.type[2].file.csv.header=Product SKU,Quantity,Status,Owner
bss.inventory.type[2].file.csv.hasHeader=true
bss.inventory.type[2].file.csv.defaultSeparator=,
bss.inventory.type[2].file.csv.fieldMapping.productSKU=COLUMN:Product SKU
bss.inventory.type[2].file.csv.fieldMapping.quantity=COLUMN:Quantity
bss.inventory.type[2].file.csv.fieldMapping.state=COLUMN:Status
bss.inventory.type[2].file.csv.fieldMapping.owner=COLUMN:Owner
bss.inventory.type[2].file.csv.fieldMapping.locationId=COLUMN:Location


#-------------------------------------------------------------------------------------
# Batch Order specific properties
#-------------------------------------------------------------------------------------

bss.order.defaultAllowedFor=NONE

bss.order.id=Generic
bss.order.allowedFor=${bss.order.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.order.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.order.processor.schedTime=0 0 1 * * ?
bss.order.processor.schedTypeDelay-sec=60
bss.order.processor.failOnError=false
bss.order.processor.chunkSize=1
# Number of chunks executed in parallel
# bss.order.processor.parallelChunkNb=10
bss.order.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.order.processor.retryDelay=10
bss.order.file.uploadDescription=Order ${bss.order.id} import file
bss.order.file.supportedFormats=CSV,JSON
bss.order.file.format=CSV
bss.order.file.csv.freemarkerTemplate=order_import.ftl
bss.order.file.csv.header=Order_Type,Product_SKU,Buyer,Seller,Reserve_Type,Start_Serial,End_Serial,Return_Type,Return_Reason,Description
bss.order.file.csv.hasHeader=true
bss.order.file.csv.defaultSeparator=,
bss.order.file.csv.fieldMapping.buyerId=COLUMN:Buyer
bss.order.file.csv.fieldMapping.sellerId=COLUMN:Seller
bss.order.file.csv.fieldMapping.items_productSku=COLUMN:Product_SKU
bss.order.file.csv.fieldMapping.items_reserveType=COLUMN:Reserve_Type
bss.order.file.csv.fieldMapping.ranges_startSerial=COLUMN:Start_Serial
bss.order.file.csv.fieldMapping.ranges_endSerial=COLUMN:End_Serial
bss.order.file.csv.fieldMapping.orderType=COLUMN:Order_Type
bss.order.file.csv.fieldMapping.returnType=COLUMN:Return_Type
bss.order.file.csv.fieldMapping.returnReason=COLUMN:Return_Reason
bss.order.file.csv.fieldMapping.clientComment=COLUMN:Description



#-------------------------------------------------------------------------------------
# Batch Reverse Order specific properties
#-------------------------------------------------------------------------------------

bss.reverseorder.defaultAllowedFor=NONE

bss.reverseorder.id=Generic
bss.reverseorder.allowedFor=${bss.reverseorder.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.reverseorder.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.reverseorder.processor.schedTime=0 0 1 * * ?
bss.reverseorder.processor.schedTypeDelay-sec=60
bss.reverseorder.processor.failOnError=false
### Keep the chunkSize=1 because currently OMS only supports chunkSize=1
bss.reverseorder.processor.chunkSize=1
# Number of chunks executed in parallel
# bss.reverseorder.processor.parallelChunkNb=10
bss.reverseorder.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.reverseorder.processor.retryDelay=10
bss.reverseorder.file.uploadDescription=Reverse order file
bss.reverseorder.file.supportedFormats=CSV,JSON
bss.reverseorder.file.format=CSV
bss.reverseorder.file.csv.freemarkerTemplate=order_reverse.ftl
bss.reverseorder.file.csv.header=OrderId,Description
bss.reverseorder.file.csv.hasHeader=true
bss.reverseorder.file.csv.defaultSeparator=,
bss.reverseorder.file.csv.fieldMapping.orderId=COLUMN:OrderId
bss.reverseorder.file.csv.fieldMapping.description=COLUMN:Description

#-------------------------------------------------------------------------------------
# Batch RateCard specific properties
#-------------------------------------------------------------------------------------

bss.ratecard.defaultAllowedFor=NONE
bss.ratecard.id=RateCard
bss.ratecard.allowedFor=${bss.ratecard.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.ratecard.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.ratecard.processor.schedTime=0 0 1 * * ?
bss.ratecard.processor.schedTypeDelay-sec=10
bss.ratecard.processor.failOnError=false
bss.ratecard.processor.chunkSize=10
# Number of chunks executed in parallel
# bss.ratecard.processor.parallelChunkNb=10
bss.ratecard.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.ratecard.processor.retryDelay=10
bss.ratecard.file.uploadDescription=${bss.ratecard.id} import file
bss.ratecard.file.supportedFormats=CSV,JSON
bss.ratecard.file.format=CSV
bss.ratecard.file.csv.freemarkerTemplate=ratecard_import.ftl
bss.ratecard.file.csv.header=Pickup Location,Drop Location,Distance(Km),Minimum Capacity(KG),Maximum Capacity(KG),Rate,Logistic Type,SelfLoad,Flat Rate Capacity(KG),Additional Rate / KG,Status,Vendor,Priority Rate
bss.ratecard.file.csv.hasHeader=true
bss.ratecard.file.csv.defaultSeparator=,
bss.ratecard.file.csv.fieldMapping.vendor=COLUMN:Vendor
bss.ratecard.file.csv.fieldMapping.pickupLocation=COLUMN:Pickup Location
bss.ratecard.file.csv.fieldMapping.dropLocation=COLUMN:Drop Location
bss.ratecard.file.csv.fieldMapping.distance=COLUMN:Distance(Km)
bss.ratecard.file.csv.fieldMapping.status=COLUMN:Status
bss.ratecard.file.csv.fieldMapping.minKg=COLUMN:Minimum Capacity(KG)
bss.ratecard.file.csv.fieldMapping.maxKg=COLUMN:Maximum Capacity(KG)
bss.ratecard.file.csv.fieldMapping.charge=COLUMN:Rate
bss.ratecard.file.csv.fieldMapping.type=COLUMN:Logistic Type
bss.ratecard.file.csv.fieldMapping.flatUptoKg=COLUMN:Flat Rate Capacity(KG)
bss.ratecard.file.csv.fieldMapping.extraChargeAfterMaxKg=COLUMN:Additional Rate / KG
bss.ratecard.file.csv.fieldMapping.selfload=COLUMN:SelfLoad
bss.ratecard.file.csv.fieldMapping.priorityRate=COLUMN:Priority Rate


#-------------------------------------------------------------------------------------
# Batch CX specific properties
#-------------------------------------------------------------------------------------

bss.cx.defaultAllowedFor=NONE

bss.cx.id=Generic
bss.cx.allowedFor=${bss.cx.defaultAllowedFor}
bss.cx.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.cx.processor.schedTime=0 0 1 * * ?
bss.cx.processor.schedTypeDelay-sec=30
bss.cx.processor.failOnError=false
#for cx use case the chunkSize must always be an even number
bss.cx.processor.chunkSize=10
# Number of chunks executed in parallel
# bss.cx.processor.parallelChunkNb=10
bss.cx.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.cx.processor.retryDelay=10
bss.cx.file.uploadDescription=CX import file
bss.cx.file.supportedFormats=CSV
bss.cx.file.format=CSV
bss.cx.file.csv.freemarkerTemplate=inventory_update.ftl
bss.cx.file.csv.header=MSISDN,SIM,date,user
bss.cx.file.csv.hasHeader=false
bss.cx.file.csv.defaultSeparator=|
bss.cx.file.csv.fieldMapping.status=CONSTANT:CX sold


#-------------------------------------------------------------------------------------
# Batch Notification specific properties
#-------------------------------------------------------------------------------------

bss.bulknotification.id=Generic
# Not Allowed in import GUI
bss.bulknotification.allowedFor=
bss.bulknotification.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.bulknotification.processor.schedTime=0 0 1 * * ?
bss.bulknotification.processor.schedTypeDelay-sec=30
bss.bulknotification.processor.failOnError=false
bss.bulknotification.processor.chunkSize=20
# Number of chunks executed in parallel
bss.bulknotification.processor.parallelChunkNb=5
bss.bulknotification.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.bulknotification.processor.retryDelay=10
bss.bulknotification.file.uploadDescription=Notification import file
bss.bulknotification.file.supportedFormats=CSV
bss.bulknotification.file.format=CSV
bss.bulknotification.file.csv.freemarkerTemplate=notification.ftl
bss.bulknotification.file.csv.header=recipient
bss.bulknotification.file.csv.hasHeader=false
bss.bulknotification.file.csv.defaultSeparator=|


#-------------------------------------------------------------------------------------
# Batch Retry Notification specific properties
#-------------------------------------------------------------------------------------

bss.retrynotification.id=Generic
# Not Allowed in import GUI
bss.retrynotification.allowedFor=
bss.retrynotification.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.retrynotification.processor.schedTime=0 0 1 * * ?
bss.retrynotification.processor.schedTypeDelay-sec=30
bss.retrynotification.processor.failOnError=false
# Only chunkSize=1 is supported
bss.retrynotification.processor.chunkSize=1
# Number of chunks executed in parallel
bss.retrynotification.processor.parallelChunkNb=10
bss.retrynotification.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.retrynotification.processor.retryDelay=10
bss.retrynotification.file.uploadDescription=Retry notification import file
bss.retrynotification.file.supportedFormats=CSV
bss.retrynotification.file.format=CSV
bss.retrynotification.file.csv.freemarkerTemplate=retry_notification.ftl
bss.retrynotification.file.csv.header=TDR
bss.retrynotification.file.csv.hasHeader=false
bss.retrynotification.file.csv.defaultSeparator=|

# Batch files by elasticsearch
#-------------------------------------------------------------------------------------
# List of the es scanners (comma separated list. can be empty)
bss.esScanners=retryNotification
# 
bss.esScanners.retryNotification.enable=false
bss.esScanners.retryNotification.batchType=RetryNotification
#bss.esScanners.retryNotification.batchSubType=
bss.esScanners.retryNotification.uploadedBy=retryES
# to avoid sending multiple notification, this esScanner for retry notitication shall be scheduled 
# at an iterval longer then the interval needed to reach the notification manager 
# cumulated with interval neeeded by it to resend and update the status in notification_data_lake_*
bss.esScanners.retryNotification.cron.schedule=0 30 * * * ?
#JSON or CSV, depend of next processing
bss.esScanners.retryNotification.line.format=JSON
#mandatory for CSV line format:
#bss.esScanners.retryNotification.line.CSV.separator=|
bss.esScanners.retryNotification.batchesPerFile=10
#batch size must not exceed 10000
bss.esScanners.retryNotification.es.batchSize=10000
bss.esScanners.retryNotification.es.query={"bool":{"must":[{"terms":{"notificationmanager.notificationMessage.status":["retriable"],"boost":1}}],"adjust_pure_negative":true,"boost":1}}
bss.esScanners.retryNotification.es.index=notification_data_lake_*


#-------------------------------------------------------------------------------------
# Batch files by FTP
#-------------------------------------------------------------------------------------
# List of the FTP directory scanners (comma separated list. can be empty)
bss.ftpFileScanners=cx
# Tunisie Telecom CX files
bss.ftpFileScanner.cx.enable=false
bss.ftpFileScanner.cx.batchType=CX
bss.ftpFileScanner.cx.uploadedBy=rcvdCX
bss.ftpFileScanner.cx.cron.schedule=0 0 3 * * ?
bss.ftpFileScanner.cx.host=localhost
#For SFTP port will be 22
bss.ftpFileScanner.cx.port=21
#It will be either FTP or SFTP, by default it will be FTP
#bss.ftpFileScanner.cx.protocol=SFTP
bss.ftpFileScanner.cx.username=cx
bss.ftpFileScanner.cx.password=seamless
bss.ftpFileScanner.cx.file.prefix=cx_
bss.ftpFileScanner.cx.directory.input=cx/uploads
bss.ftpFileScanner.cx.directory.stage=cx/uploads/stage
bss.ftpFileScanner.cx.directory.failed=cx/uploads/validations-not-successful
bss.ftpFileScanner.cx.directory.processed=cx/uploads/processed																			  

#-------------------------------------------------------------------------------------
# Batch files by Local Directory Scanning
#-------------------------------------------------------------------------------------
# List of the Local directory scanners (comma separated list. can be empty)
bss.localFileScanners=cx
# Tunisie Telecom CX files
bss.localFileScanner.cx.enable=false
bss.localFileScanner.cx.batchType=CX
bss.localFileScanner.cx.uploadedBy=rcvdCX
bss.localFileScanner.cx.cron.schedule=0 0 4 * * ?
bss.localFileScanner.cx.file.prefix=cx_
bss.localFileScanner.cx.directory.input=/home/admin/batch-scheduling/cx/uploads
bss.localFileScanner.cx.directory.stage=/home/admin/batch-scheduling/cx/uploads/stage
bss.localFileScanner.cx.directory.failed=/home/admin/batch-scheduling/cx/uploads/validations-not-successful
bss.localFileScanner.cx.directory.processed=/home/admin/batch-scheduling/cx/uploads/processed															 
#-------------------------------------------------------------------------------------
# Get Scheduled Batches, Get Import Info and Get Batch Info specific properties
#-------------------------------------------------------------------------------------
bss.history.visibleFor=Dealer,Sub Dealer
#bss.history.visibleFor=ALL

#-------------------------------------------------------------------------------------
# Data Feeder properties
#-------------------------------------------------------------------------------------
dataFeed.freemarker.file.path=/opt/seamless/conf/batch-scheduling/datafeeder/templates
threadpoolmanager.pools.dataFeed.targetId=com.seamless.common.data.dump.dataFeed
threadpoolmanager.pools.dataFeed.corePoolSize=25
threadpoolmanager.pools.dataFeed.maxPoolSize=40
threadpoolmanager.pools.dataFeed.keepAliveTime=60000
threadpoolmanager.pools.dataFeed.keepAliveTimeUnit=MILLISECONDS

dataFeed.version=1
#dataFeed.componentName=batchscheduling
dataFeed.componentName=bss
dataFeed.eventType=Report

#template.IMPORT_RATECARD=batchschedulingFeed_importGeneric.ftl
template.IMPORT_INVENTORY=batchschedulingFeed_importGeneric.ftl
#template.IMPORT_RESELLER=batchschedulingFeed_importGeneric.ftl
#template.IMPORT_RESELLER_USER=batchschedulingFeed_importGeneric.ftl
#template.IMPORT_ORDER=batchschedulingFeed_importGeneric.ftl
#template.IMPORT_REVERSEORDER=batchschedulingFeed_importGeneric.ftl
template.IMPORT_RESUBMIT=batchschedulingFeed_importGeneric.ftl
template.GET_IMPORT_INFO=batchschedulingFeed_importGeneric.ftl
template.GET_SERVICE_INFO=batchschedulingFeed_serviceInfo.ftl
template.GET_BATCH_INFO=batchschedulingFeed_batchInfo.ftl
template.GET_SCHEDULED_BATCHES=batchschedulingFeed_scheduledBatches.ftl
#template.IMPORT_TRANSACTION=batchschedulingFeed_importGeneric.ftl
template.UPDATE_IMPORT_TASK=batchschedulingFeed_updateImportTask.ftl
template.IMPORT_NOTIFICATION=batchschedulingFeed_importNotification.ftl


#-------------------------------------------------------------------------------------
# Batch Transaction specific properties
#-------------------------------------------------------------------------------------

bss.transaction.defaultAllowedFor=NONE

bss.transaction.id=Generic
bss.transaction.allowedFor=${bss.transaction.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.transaction.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.transaction.processor.schedTime=0 0 1 * * ?
bss.transaction.processor.schedTypeDelay-sec=60
bss.transaction.processor.failOnError=false
bss.transaction.processor.chunkSize=10
# Number of chunks executed in parallel
# bss.transaction.processor.parallelChunkNb=10
bss.transaction.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.transaction.processor.retryDelay=10
bss.transaction.file.uploadDescription=transaction ${bss.transaction.id} import file
bss.transaction.file.supportedFormats=CSV,JSON
bss.transaction.file.format=CSV
bss.transaction.file.csv.freemarkerTemplate=transaction_o2c_foc_import.ftl
bss.transaction.file.csv.header=senderMsisdn,receiverMsisdn,amount,productSku
bss.transaction.file.csv.hasHeader=true
bss.transaction.file.csv.defaultSeparator=,
bss.transaction.file.csv.fieldMapping.senderId=COLUMN:senderMsisdn
bss.transaction.file.csv.fieldMapping.receiverId=COLUMN:receiverMsisdn
bss.transaction.file.csv.fieldMapping.value=COLUMN:amount
bss.transaction.file.csv.fieldMapping.productSKU=COLUMN:productSku
#left side fields need to match with txe request
#-------------------------------------------------------------------------------------
# Batch Scheduling for campaign targets
#-------------------------------------------------------------------------------------

bss.campaigntargets.defaultAllowedFor=NONE

bss.campaigntargets.id=campaignTargets
bss.campaigntargets.allowedFor=${bss.campaigntargets.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.campaigntargets.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.campaigntargets.processor.schedTime=0 0 1 * * ?
bss.campaigntargets.processor.schedTypeDelay-sec=60
bss.campaigntargets.processor.failOnError=false
bss.campaigntargets.processor.chunkSize=10
bss.campaigntargets.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.campaigntargets.processor.retryDelay=10
bss.campaigntargets.file.uploadDescription=campaigntargets ${bss.campaigntargets.id} import file
bss.campaigntargets.file.supportedFormats=CSV,JSON
bss.campaigntargets.file.format=CSV
bss.campaigntargets.file.csv.freemarkerTemplate=campaign_targets.ftl
bss.campaigntargets.file.csv.header=resellerMSISDN,campaignId,kpiName,event,target
bss.campaigntargets.file.csv.hasHeader=true
bss.campaigntargets.file.csv.defaultSeparator=,
bss.campaigntargets.file.csv.fieldMapping.resellerMSISDN=COLUMN:resellerMSISDN
bss.campaigntargets.file.csv.fieldMapping.sellerId=COLUMN:Seller
bss.campaigntargets.file.csv.fieldMapping.campaignId=COLUMN:campaignId
bss.campaigntargets.file.csv.fieldMapping.kpiName=COLUMN:kpiName
bss.campaigntargets.file.csv.fieldMapping.event=COLUMN:event
bss.campaigntargets.file.csv.fieldMapping.target=COLUMN:target

##### Release Aug 22 1.20.0 #######

# Turn this property to true to create a failed batch task when the validation
# of the format of the batch file fails.
# When set to false then the invalid files are not present in the batch history
bss.store.invalid.file=true

bss.dmsApi.changeResellerParentUri=/v2/auth/bulkChangeParent

## List of columns that must have a unique/single value
## In this example all lines of the file must have the same Status and all lines must have the same Owner
#bss.inventory.type[1].file.csv.fieldValidationUnique=Status,Owner

template.IMPORT_PRODUCT=batchschedulingFeed_importGeneric.ftl
template.IMPORT_CONTRACT=batchschedulingFeed_importGeneric.ftl
template.IMPORT_RESELLER_CHANGE_PARENT=batchschedulingFeed_importGeneric.ftl

#-------------------------------------------------------------------------------------
# Product (through nginx)
#-------------------------------------------------------------------------------------
 
bss.product.url=http://svc-product-management:8012/pms
bss.product.importProductUri=/v1/product-variant-bulk/create
bss.product.connectionTimeout=5000
bss.product.requestTimeout=60000

#-------------------------------------------------------------------------------------
# Batch product for Generic
#-------------------------------------------------------------------------------------
bss.product.defaultAllowedFor=ALL
 
bss.product.id=Product_Variant
bss.product.allowedFor=${bss.product.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.product.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.product.processor.schedTime=0/20 * * * * ?
bss.product.processor.schedTypeDelay-sec=20
bss.product.processor.failOnError=true
bss.product.processor.chunkSize=10
bss.product.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.product.processor.retryDelay=10
bss.product.file.uploadDescription=product ${bss.product.id} import file
bss.product.file.supportedFormats=CSV
bss.product.file.format=CSV
bss.product.file.csv.freemarkerTemplate=product_import.ftl
bss.product.file.csv.header=product_code,product_sku,supplier_ref,ean_code,status,upsell_option,currency,unit_price,variable_price,upSellProducts,c2s_rule,service_type,gateway_code,reseller_type,operation
bss.product.file.csv.hasHeader=true
bss.product.file.csv.defaultSeparator=,
bss.product.file.csv.fieldMapping.productCode=COLUMN:product_code
bss.product.file.csv.fieldMapping.productSKU=COLUMN:product_sku
bss.product.file.csv.fieldMapping.status=COLUMN:status
bss.product.file.csv.fieldMapping.supplierReference=COLUMN:supplier_ref
bss.product.file.csv.fieldMapping.eanCode=COLUMN:ean_code
bss.product.file.csv.fieldMapping.upsellOption=COLUMN:upsell_option
bss.product.file.csv.fieldMapping.currency=COLUMN:currency
bss.product.file.csv.fieldMapping.price=COLUMN:unit_price
bss.product.file.csv.fieldMapping.variablePrice=COLUMN:variable_price
bss.product.file.csv.fieldMapping.upSellProducts=COLUMN:upSellProducts
bss.product.file.csv.fieldMapping.associateRule=COLUMN:c2s_rule
bss.product.file.csv.fieldMapping.serviceType=COLUMN:service_type
bss.product.file.csv.fieldMapping.gwCode=COLUMN:gateway_code
bss.product.file.csv.fieldMapping.resellerType=COLUMN:reseller_type
bss.product.file.csv.fieldMapping.operation=COLUMN:operation

#-------------------------------------------------------------------------------------
# ChangeParent properties
#-------------------------------------------------------------------------------------
 
bss.resellerchangeparent.defaultAllowedFor=NONE
bss.resellerchangeparent.id=ChangeParent
#bss.resellerchangeparent.id=Parent
#bss.resellerchangeparent.updateSubType=ChangeParent
bss.resellerchangeparent.processor.schedType=immediate
bss.resellerchangeparent.allowedFor=${bss.resellerchangeparent.defaultAllowedFor}
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.resellerchangeparent.processor.schedTime=0 0 1 * * ?
bss.resellerchangeparent.processor.schedTypeDelay-sec=60
bss.resellerchangeparent.processor.failOnError=false
bss.resellerchangeparent.processor.chunkSize=10
bss.resellerchangeparent.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.resellerchangeparent.processor.retryDelay=10
bss.resellerchangeparent.file.uploadedBy=rcvdReseller
bss.resellerchangeparent.file.uploadDescription=Reseller ${bss.resellerchangeparent.id} import file
bss.resellerchangeparent.file.supportedFormats=CSV,JSON
bss.resellerchangeparent.file.format=CSV
bss.resellerchangeparent.file.csv.freemarkerTemplate=reseller_change_parent.ftl
bss.resellerchangeparent.file.csv.header=RESELLER_ID,NEW_RESELLER_PARENT_ID
bss.resellerchangeparent.file.csv.hasHeader=true
bss.resellerchangeparent.file.csv.defaultSeparator=,
bss.resellerchangeparent.file.csv.fieldMapping.resellerId=COLUMN:RESELLER_ID
bss.resellerchangeparent.file.csv.fieldMapping.newResellerParentId=COLUMN:NEW_RESELLER_PARENT_ID

 




